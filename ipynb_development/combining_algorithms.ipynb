{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faad88dc-4ac2-4785-aaeb-a9e0688e597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка работоспособности 2-х моделей  разбиением пользователей\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5631146c-40ed-48a4-9452-111b9efe9855",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\n",
    "    \"postgresql://robot-startml-ro:pheiph0hahj1Vaif@\"\n",
    "    \"postgres.lab.karpov.courses:6432/startml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "178051aa-346c-4477-acf6-6393d8873402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_load_sql(query: str) -> pd.DataFrame:\n",
    "    CHUNKSIZE = 200000\n",
    "    engine = create_engine(\n",
    "        \"postgresql://robot-startml-ro:pheiph0hahj1Vaif@\"\n",
    "        \"postgres.lab.karpov.courses:6432/startml\"\n",
    "    )\n",
    "    conn = engine.connect().execution_options(stream_results=True)\n",
    "    chunks = []\n",
    "    for chunk_dataframe in pd.read_sql(query, conn, chunksize=CHUNKSIZE):\n",
    "        chunks.append(chunk_dataframe)\n",
    "    conn.close()\n",
    "    return pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5dcd164-c76b-40f5-bfbe-5bc243e7fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для get_exp_group нужны только users\n",
    "user_data = pd.read_sql('SELECT * FROM public.user_data', con = engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c92fb9d5-0aed-469b-b09a-98ca5888add8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 200 в группе: test\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "def get_exp_group(user_id: int) -> str:\n",
    "    salt = 'my_salt'\n",
    "    group_count = 2\n",
    "    value_str = str(user_id) + salt\n",
    "    value_num = int(hashlib.md5(value_str.encode()).hexdigest(), 16)\n",
    "    if value_num % group_count == 0:\n",
    "        return 'test'\n",
    "    else:\n",
    "        return 'control'\n",
    "\n",
    "#group = get_exp_group(80000)\n",
    "#print(f\"User 200 в группе: {group}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7e1ed1a-ff1b-4b41-875c-269bd8126552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features() -> pd.DataFrame:\n",
    "    feed_data = batch_load_sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM public.feed_data\n",
    "        WHERE action='like'\n",
    "        limit 9000000\"\"\")\n",
    "    return feed_data\n",
    "\n",
    "preprocess_posts_new = pd.read_sql('SELECT * FROM public.kazakov_mta3669_features_dl', con = engine)\n",
    "posts = pd.read_sql('SELECT * FROM public.post_text_df', con = engine)\n",
    "posts.set_index('post_id', inplace=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "525b506b-d0e0-484e-9fe4-58c4a1374c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_path(path: str, exp_group: str) -> str:\n",
    "    \"\"\"Полный путь к модели с учетом среды и группы\"\"\"\n",
    "    if os.environ.get(\"IS_LMS\") == \"1\":\n",
    "        base_dir = '/workdir/user_input/'\n",
    "        model_dir = 'model_test' if exp_group == 'test' else 'model_control'\n",
    "        return os.path.join(base_dir, model_dir, os.path.basename(path))\n",
    "    return path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df36e24e-2965-46bc-9745-4c29eb5b08fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-01 06:09:21\n",
      "2021-12-29 23:46:10\n",
      "200\n",
      "168552\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "#features_data = load_features()\n",
    "print(features_data['timestamp'].min())\n",
    "print(features_data['timestamp'].max())\n",
    "print(user_data['user_id'].min())\n",
    "print(user_data['user_id'].max())\n",
    "print(user_data['user_id'].shape[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "014dd240-2fcb-481b-b234-320a3b20019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = {\n",
    "    'id': 160000,\n",
    "    'time': datetime(2023, 5, 17),\n",
    "    'limit': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "abdc2e10-04e4-45fc-a08b-f7def4da1036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(exp_group: str, model_filename: str) -> CatBoostClassifier:\n",
    "    \"\"\"Загрузка модели для указанной группы\"\"\"\n",
    "    model_path = get_model_path(model_filename, exp_group)\n",
    "    model = CatBoostClassifier()\n",
    "    model.load_model(model_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bc04558b-3c66-4d1d-8723-cb800a45bde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_control = load_model('control', 'catboost.cbm')\n",
    "model_test = load_model('test', 'catboost_model_mta3669.cbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6e2a2f5c-5c4f-4b79-909e-63ee907003bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция классического ML\n",
    "def recommendations_ML(id: int, time: datetime, limit: int):\n",
    "    user_view_posts = features_data[features_data['user_id'] == id]['post_id'].unique() \n",
    "    select_posts = preprocess_posts[~preprocess_posts['post_id'].isin(user_view_posts)]\n",
    "    user_init = user_data[user_data['user_id'] == id]\n",
    "    select_posts_use = select_posts.copy() \n",
    "    for col in user_init.columns:\n",
    "        select_posts_use = select_posts_use.assign(**{col: user_init[col].iloc[0]})\n",
    "    select_posts_use = select_posts_use.set_index(['user_id', 'post_id'])\n",
    "    viewing_posts = features_data[features_data['user_id'] == id]['target'].count()\n",
    "    like_posts = features_data[(features_data['user_id'] == id) & (features_data['target'] == 1)]['target'].count()\n",
    "    like_frequency = like_posts / viewing_posts if viewing_posts > 0 else 0\n",
    "    user_dates = features_data[features_data['user_id'] == id]['timestamp']\n",
    "    mean_date = user_dates.mean()\n",
    "    min_date = user_dates.min()\n",
    "    select_posts_use['target'] = like_frequency\n",
    "    select_posts_use['min_date'] = min_date\n",
    "    categorical_features = ['country', 'city', 'os', 'source']\n",
    "    C = 0.006\n",
    "    for col in categorical_features:\n",
    "        if col in ['os', 'source']:\n",
    "            if select_posts_use[col].nunique() == 2: \n",
    "                dummies = pd.get_dummies(select_posts_use[col], prefix=col, dtype=int, drop_first=True)\n",
    "                select_posts_use = pd.concat([select_posts_use, dummies], axis=1)\n",
    "                select_posts_use = select_posts_use.drop(col, axis=1)\n",
    "            else:\n",
    "                if col == 'os':\n",
    "                    select_posts_use['os_iOS'] = (select_posts_use[col] == 'iOS').astype(int)\n",
    "                elif col == 'source':\n",
    "                    select_posts_use['source_organic'] = (select_posts_use[col] == 'organic').astype(int)\n",
    "                select_posts_use = select_posts_use.drop(col, axis=1)\n",
    "        else:\n",
    "            means = select_posts_use.groupby(col)['target'].mean()\n",
    "            noisy_means = means + C * np.random.randn(len(means))\n",
    "            mapping_dict = noisy_means.to_dict()\n",
    "            select_posts_use[col] = select_posts_use[col].map(mapping_dict)\n",
    "    \n",
    "    select_posts_use = select_posts_use.drop(['target'], axis = 1) \n",
    "    select_posts_use['day'] = select_posts_use['min_date'].dt.dayofweek\n",
    "    select_posts_use['month'] = select_posts_use['min_date'].dt.month\n",
    "    select_posts_use['hour'] = select_posts_use['min_date'].dt.hour\n",
    "    select_posts_use = select_posts_use.drop(['min_date'],axis=1)\n",
    "    \n",
    "    #expected_features = model_control.feature_names_\n",
    "    #print(\"Ожидаемые признаки:\", expected_features)\n",
    "    #print(\"Фактические признаки:\", select_posts_use.columns.tolist())\n",
    "    \n",
    "    select_posts_use['predict'] = model_control.predict_proba(select_posts_use)[:,1]\n",
    "    typle_idx = select_posts_use['predict'].nlargest(limit).index.tolist()\n",
    "    posts_idx = []\n",
    "    for item in typle_idx:\n",
    "        posts_idx.append(item[1])\n",
    "    #Вывести мы должны список из словарей\n",
    "    final_posts = []\n",
    "    for idx in posts_idx:\n",
    "        myDict = {\n",
    "            'id':  idx,\n",
    "            'text': posts.loc[idx, 'text'],\n",
    "            'topic': posts.loc[idx, 'topic'],\n",
    "        }\n",
    "        final_posts.append(myDict)\n",
    "    #accord = {'exp_group': 'control'}\n",
    "    #final_posts.append(accord)\n",
    "    return final_posts\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a70e4a58-215e-416e-8305-3fdee62f63c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция DL\n",
    "def recommendations_DL(id: int, time: datetime, limit: int):\n",
    "    # Сначала удалим посты из выборки, которые пользователь уже видел\n",
    "    user_view_posts = (features_data[features_data['user_id'] == id]\n",
    "    [['post_id', 'timestamp']].drop_duplicates(subset=['post_id']).reset_index(drop=True)\n",
    "                      )\n",
    "    viewed_ids = user_view_posts['post_id'].tolist() \n",
    "    select_posts = preprocess_posts_new[~preprocess_posts_new['post_id'].isin(viewed_ids)]\n",
    "    #return select_posts\n",
    "    # определим фичи конкретного юзера\n",
    "    user_init = user_data[user_data['user_id'] == id]\n",
    "    # Добавляем их к табл. select_posts\n",
    "    select_posts_use = select_posts.copy()\n",
    "    user_dates = features_data[features_data['user_id'] == id]['timestamp']\n",
    "    user_dates_mean = user_dates.mean()\n",
    "    select_posts_use.insert(0, 'month', user_dates_mean.month)\n",
    "    select_posts_use.insert(1, 'hour', user_dates_mean.hour)\n",
    "    for col in user_init.columns:\n",
    "        select_posts_use = select_posts_use.assign(**{col: user_init[col].iloc[0]})\n",
    "    new_order = list(user_init.columns) + [col for col in select_posts_use.columns if col not in user_init.columns]\n",
    "    select_posts_use = select_posts_use[new_order]\n",
    "    # Создаем мультииндекс user_id / post_id\n",
    "    select_posts_use = select_posts_use.set_index(['user_id', 'post_id'])\n",
    "    select_posts_use.drop(['index'], axis = 1, inplace=True)\n",
    "    select_posts_use['predict'] = model_test.predict_proba(select_posts_use)[:,1]\n",
    "    #return select_posts_use\n",
    "    typle_idx = select_posts_use['predict'].nlargest(limit).index.tolist()\n",
    "    posts_idx = []\n",
    "    for item in typle_idx:\n",
    "        posts_idx.append(item[1])\n",
    "    #Вывести должны мы список из словарей\n",
    "    final_posts = []\n",
    "    for idx in posts_idx:\n",
    "        myDict = {\n",
    "            'id':  idx,\n",
    "            'text': posts.loc[idx, 'text'],\n",
    "            'topic': posts.loc[idx, 'topic'],\n",
    "        }\n",
    "        final_posts.append(myDict)\n",
    "    #accord = {'exp_group': 'test'}\n",
    "    #final_posts.append(accord)\n",
    "    return final_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "894534e0-63f6-4bd9-9b3e-404ea4838cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-06 16:37:31.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mML model for user 160000\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 332,\n",
       "  'text': 'LSE sets date for takeover deal\\n\\nThe London Stock Exchange (LSE) is planning to announce a preferred takeover by the end of the month, newspaper reports claim.\\n\\nThe Sunday Telegraph said the LSEs plan was further evidence it wants to retain tight control over its destiny. Both Deutsche Boerse and rival Euronext held talks with the London market last week over a possible offer. A £1.3bn offer from Deutsche Boerse has already been rejected, while Euronext has said it will make an all cash bid. Speculation suggests that Paris-based Euronext has the facilities in place to make a bid of £1.4bn, while its German rival may up its bid to the £1.5bn mark. Neither has yet tabled a formal bid, but the LSE is expected to hold further talks with the two parties later this week. However, the Sunday Telegraph report added that there are signs that Deutsche Boerse chief executive Werner Seifert is becoming increasingly impatient with the LSEs managed bid process.\\n\\nDespite insisting he wants to agree a recommended deal with the LSEs board, the newspaper suggested he may pull out of the process and put an offer directly to shareholders instead. The newspaper also claimed Mr Seifert was becoming increasingly frustrated with the pace of negotiations since Deutsche Boerses £1.3bn offer was rejected in mid-December, in particular the LSEs decision to suspend talks over the Christmas period. Meanwhile, the German exchanges offer has come under fire recently. Unions for Deutsche Boerse staff in Frankfurt have reportedly expressed fears that up to 300 jobs would be moved to London if the takeover is successful. Others claim it will weaken the citys status as Europes financial centre, while German politicians are also said to be angry over the market operators promise to move its headquarters to London if a bid is successful. A further stumbling block is Deutsche Boerses control over its Clearstream unit, the clearing house that processes securities transactions. LSE shareholders fear it would create a monopoly situation, weakening the position of shareholders when negotiating lower transaction fees for share dealings. LSE and Euronext do not have control over their clearing and settlement operations, a situation which critics say is more transparent and competitive.\\n',\n",
       "  'topic': 'business'},\n",
       " {'id': 15,\n",
       "  'text': 'Euronext poised to make LSE bid\\n\\nPan-European group Euronext is poised to launch a bid for the London Stock Exchange, UK media reports say.\\n\\nLast week, the LSE rejected a takeover proposal from German rival Deutsche Boerse - the 530 pence-a-share offer valued the exchange at about £1.35bn. The LSE, which saw its shares rise 25%, said the bid undervalued the business. Euronext - formed after the Brussels, Paris and Amsterdam exchanges merged - is reportedly working with three investment banks on a possible offer. The LSE, Europes biggest stock market, is a key prize, listing stocks with a total capitalisation of £1.4 trillion.\\n\\nEuronext already has a presence in London due to its 2001 acquisition of London-based options and futures exchange Liffe. Trades on the LSE are cleared via Clearnet, in which Euronext has a quarter stake.\\n\\nEuronext, which also operates an exchange in Lisbon, last week appointed UBS and ABN Amro as additional advisors. It is also working with Morgan Stanley. Despite the rejection of the Deutsche Boerse bid last week, Werner Seifert, chief executive of the Frankfurt-based exchange, may well come back with an improved offer. It has long wanted to link up with London, and the two tried and failed to seal a merger in 2000. Responding to the LSEs rebuff, Deutsche Boerse - whose market capitalisation is more than £3bn - said it believed it could show its proposal offered benefits, and that it still hoped to make a cash bid.\\n\\nLast week the LSE said not only was the bid undervalued, but that it had been advised that there can be no assurance that any transaction could be successfully implemented. However, it has indicated it is open for further talks. Meanwhile, German magazine Der Spiegel said part of Mr Seiferts negotiations with the LSE were about where to base the future board of any merged exchange. While Mr Seifert has suggested a merged company would be run out of London, the mayor of Frankfurt has raised concerns that such a move could cost German jobs. Many analysts believe German Boerse has more financial firepower than Euronext if it came to a bidding war.\\n',\n",
       "  'topic': 'business'},\n",
       " {'id': 239,\n",
       "  'text': 'Standard Life concern at LSE bid\\n\\nStandard Life is the latest shareholder in Deutsche Boerse to express concern at the German stock market operators plans to buy the London Stock Exchange.\\n\\nIt said Deutsche Boerse had to show why its planned £1.35bn ($2.5bn) offer for the LSE was good for shareholder value. Reports say Standard Life, which owns a 1% stake in Deutsche Boerse, may seek a shareholder vote on the issue. Fellow shareholders US-based hedge fund Atticus Capital and UK-based TCI Fund Management have also expressed doubts.\\n\\nDeutsche Boerses supervisory board has approved the possible takeover of the LSE despite the signs of opposition from investors. The onus is on Deutsche Boerses management to demonstrate why the purchase of the LSE creates more value for shareholders than other strategies, such as a buyback, said Richard Moffat, investment director of UK Equities at Standard Life Investments. Atticus Capital, holding 2% of Deutsche Boerse, wants it to buy back its own shares rather than buy the LSE. And TCI which holds about 5%, has made a request for an extraordinary shareholders meeting to be held to vote on replacing the companys entire supervisory board. It has also demanded that shareholders be consulted about the proposed acquisition, and whether the operator of the Frankfurt stock exchange should return $500m (£266m) to shareholders instead.\\n\\nIn December, Deutsche Boerse, which also owns the derivatives market Eurex and the clearing firm Clearstream, put an informal offer of 530 pence per LSE share on the table. However, the LSE said the cash offer undervalued both its own business and the benefits of such a tie-up. Since then an improved offer from Deutsche Boerse has been anticipated as its management has continued talks with LSE chief executive Clara Furse. But the London exchange is also holding talks with Deutsche Boerses rival Euronext, which operates the Amsterdam, Brussels, Lisbon and Paris exchanges, as well as London-based international derivatives market Liffe.\\n',\n",
       "  'topic': 'business'},\n",
       " {'exp_group': 'control'}]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_group = get_exp_group(request['id'])\n",
    "if exp_group == 'test':\n",
    "    logger.info(f'Dl model for user {request['id']}')\n",
    "    output_function = recommendations_DL(request['id'], request['time'], request['limit'])\n",
    "    output_function.append({'exp_group': 'test'})\n",
    "elif exp_group == 'control':\n",
    "    logger.info(f'ML model for user {request['id']}')\n",
    "    output_function = recommendations_ML(request['id'], request['time'], request['limit'])\n",
    "    output_function.append({'exp_group': 'control'})\n",
    "else:\n",
    "  raise ValueError('unknown group')\n",
    "    \n",
    "output_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "37915277-ed48-41ae-ba09-aa4579a9b308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>Компонента 1</th>\n",
       "      <th>Компонента 2</th>\n",
       "      <th>Компонента 3</th>\n",
       "      <th>Компонента 4</th>\n",
       "      <th>Компонента 5</th>\n",
       "      <th>Компонента 6</th>\n",
       "      <th>Компонента 7</th>\n",
       "      <th>Компонента 8</th>\n",
       "      <th>Компонента 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Компонента 97</th>\n",
       "      <th>Компонента 98</th>\n",
       "      <th>Компонента 99</th>\n",
       "      <th>Компонента 100</th>\n",
       "      <th>covid</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>movie</th>\n",
       "      <th>politics</th>\n",
       "      <th>sport</th>\n",
       "      <th>tech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.116060</td>\n",
       "      <td>-0.186410</td>\n",
       "      <td>-0.049454</td>\n",
       "      <td>-0.000525</td>\n",
       "      <td>-0.101009</td>\n",
       "      <td>-0.133808</td>\n",
       "      <td>-0.202089</td>\n",
       "      <td>-0.065688</td>\n",
       "      <td>-0.073895</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010917</td>\n",
       "      <td>-0.025841</td>\n",
       "      <td>0.028009</td>\n",
       "      <td>-0.051560</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.144863</td>\n",
       "      <td>-0.213865</td>\n",
       "      <td>-0.057816</td>\n",
       "      <td>-0.049957</td>\n",
       "      <td>0.040709</td>\n",
       "      <td>-0.041332</td>\n",
       "      <td>-0.027845</td>\n",
       "      <td>0.008899</td>\n",
       "      <td>-0.021784</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023653</td>\n",
       "      <td>-0.093682</td>\n",
       "      <td>-0.024064</td>\n",
       "      <td>-0.051820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.124525</td>\n",
       "      <td>-0.147405</td>\n",
       "      <td>-0.033435</td>\n",
       "      <td>0.010892</td>\n",
       "      <td>-0.114626</td>\n",
       "      <td>-0.132842</td>\n",
       "      <td>-0.157777</td>\n",
       "      <td>-0.064754</td>\n",
       "      <td>-0.007903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.013621</td>\n",
       "      <td>0.048129</td>\n",
       "      <td>-0.032911</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.099042</td>\n",
       "      <td>-0.150082</td>\n",
       "      <td>-0.023253</td>\n",
       "      <td>-0.003138</td>\n",
       "      <td>-0.075870</td>\n",
       "      <td>-0.127194</td>\n",
       "      <td>-0.110220</td>\n",
       "      <td>-0.029244</td>\n",
       "      <td>0.039262</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042204</td>\n",
       "      <td>-0.018020</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.064908</td>\n",
       "      <td>-0.077954</td>\n",
       "      <td>-0.022646</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>-0.032227</td>\n",
       "      <td>-0.038098</td>\n",
       "      <td>-0.007134</td>\n",
       "      <td>0.005762</td>\n",
       "      <td>0.010590</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032575</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.034106</td>\n",
       "      <td>-0.026841</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7018</th>\n",
       "      <td>7315</td>\n",
       "      <td>0.254660</td>\n",
       "      <td>0.124200</td>\n",
       "      <td>0.017228</td>\n",
       "      <td>-0.143192</td>\n",
       "      <td>-0.034008</td>\n",
       "      <td>0.014999</td>\n",
       "      <td>0.008834</td>\n",
       "      <td>-0.018330</td>\n",
       "      <td>0.056926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035077</td>\n",
       "      <td>-0.008423</td>\n",
       "      <td>0.033310</td>\n",
       "      <td>0.016169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7019</th>\n",
       "      <td>7316</td>\n",
       "      <td>0.209761</td>\n",
       "      <td>0.108771</td>\n",
       "      <td>0.014662</td>\n",
       "      <td>-0.092212</td>\n",
       "      <td>-0.014201</td>\n",
       "      <td>-0.046052</td>\n",
       "      <td>-0.001107</td>\n",
       "      <td>0.022673</td>\n",
       "      <td>-0.030220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.023937</td>\n",
       "      <td>-0.048789</td>\n",
       "      <td>-0.027441</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7020</th>\n",
       "      <td>7317</td>\n",
       "      <td>0.138492</td>\n",
       "      <td>0.056343</td>\n",
       "      <td>0.003408</td>\n",
       "      <td>0.115936</td>\n",
       "      <td>0.076048</td>\n",
       "      <td>-0.027877</td>\n",
       "      <td>0.013407</td>\n",
       "      <td>-0.041453</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013270</td>\n",
       "      <td>-0.021687</td>\n",
       "      <td>-0.027060</td>\n",
       "      <td>-0.012615</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7021</th>\n",
       "      <td>7318</td>\n",
       "      <td>0.200977</td>\n",
       "      <td>0.030445</td>\n",
       "      <td>-0.010369</td>\n",
       "      <td>0.093321</td>\n",
       "      <td>0.052157</td>\n",
       "      <td>0.010094</td>\n",
       "      <td>-0.014525</td>\n",
       "      <td>0.010085</td>\n",
       "      <td>0.099764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023916</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>-0.005310</td>\n",
       "      <td>0.009476</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7022</th>\n",
       "      <td>7319</td>\n",
       "      <td>0.108468</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>0.009749</td>\n",
       "      <td>0.024122</td>\n",
       "      <td>0.015741</td>\n",
       "      <td>-0.013621</td>\n",
       "      <td>0.013159</td>\n",
       "      <td>-0.002775</td>\n",
       "      <td>-0.025187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>-0.001169</td>\n",
       "      <td>0.014847</td>\n",
       "      <td>0.022737</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7023 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      post_id  Компонента 1  Компонента 2  Компонента 3  Компонента 4  \\\n",
       "0           1      0.116060     -0.186410     -0.049454     -0.000525   \n",
       "1           2      0.144863     -0.213865     -0.057816     -0.049957   \n",
       "2           3      0.124525     -0.147405     -0.033435      0.010892   \n",
       "3           4      0.099042     -0.150082     -0.023253     -0.003138   \n",
       "4           5      0.064908     -0.077954     -0.022646      0.000431   \n",
       "...       ...           ...           ...           ...           ...   \n",
       "7018     7315      0.254660      0.124200      0.017228     -0.143192   \n",
       "7019     7316      0.209761      0.108771      0.014662     -0.092212   \n",
       "7020     7317      0.138492      0.056343      0.003408      0.115936   \n",
       "7021     7318      0.200977      0.030445     -0.010369      0.093321   \n",
       "7022     7319      0.108468      0.020384      0.009749      0.024122   \n",
       "\n",
       "      Компонента 5  Компонента 6  Компонента 7  Компонента 8  Компонента 9  \\\n",
       "0        -0.101009     -0.133808     -0.202089     -0.065688     -0.073895   \n",
       "1         0.040709     -0.041332     -0.027845      0.008899     -0.021784   \n",
       "2        -0.114626     -0.132842     -0.157777     -0.064754     -0.007903   \n",
       "3        -0.075870     -0.127194     -0.110220     -0.029244      0.039262   \n",
       "4        -0.032227     -0.038098     -0.007134      0.005762      0.010590   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "7018     -0.034008      0.014999      0.008834     -0.018330      0.056926   \n",
       "7019     -0.014201     -0.046052     -0.001107      0.022673     -0.030220   \n",
       "7020      0.076048     -0.027877      0.013407     -0.041453      0.004192   \n",
       "7021      0.052157      0.010094     -0.014525      0.010085      0.099764   \n",
       "7022      0.015741     -0.013621      0.013159     -0.002775     -0.025187   \n",
       "\n",
       "      ...  Компонента 97  Компонента 98  Компонента 99  Компонента 100  covid  \\\n",
       "0     ...      -0.010917      -0.025841       0.028009       -0.051560      0   \n",
       "1     ...      -0.023653      -0.093682      -0.024064       -0.051820      0   \n",
       "2     ...       0.009781       0.013621       0.048129       -0.032911      0   \n",
       "3     ...      -0.042204      -0.018020       0.000902        0.000216      0   \n",
       "4     ...      -0.032575       0.000287       0.034106       -0.026841      0   \n",
       "...   ...            ...            ...            ...             ...    ...   \n",
       "7018  ...       0.035077      -0.008423       0.033310        0.016169      0   \n",
       "7019  ...       0.002406       0.023937      -0.048789       -0.027441      0   \n",
       "7020  ...      -0.013270      -0.021687      -0.027060       -0.012615      0   \n",
       "7021  ...       0.023916       0.000117      -0.005310        0.009476      0   \n",
       "7022  ...       0.003334      -0.001169       0.014847        0.022737      0   \n",
       "\n",
       "      entertainment  movie  politics  sport  tech  \n",
       "0                 0      0         0      0     0  \n",
       "1                 0      0         0      0     0  \n",
       "2                 0      0         0      0     0  \n",
       "3                 0      0         0      0     0  \n",
       "4                 0      0         0      0     0  \n",
       "...             ...    ...       ...    ...   ...  \n",
       "7018              0      1         0      0     0  \n",
       "7019              0      1         0      0     0  \n",
       "7020              0      1         0      0     0  \n",
       "7021              0      1         0      0     0  \n",
       "7022              0      1         0      0     0  \n",
       "\n",
       "[7023 rows x 107 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "398029ce-ec2f-4214-8b04-15fff1339a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'control'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_group = get_exp_group(request['id'])\n",
    "exp_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "04c7ada7-f64c-4132-9ccf-e0e3af1a6ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_posts = pd.read_sql('SELECT * FROM public.preprocess_posts', con = engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1950cd35-498b-431d-ae39-52521d6888d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test group: 50.10%\n",
      "Control group: 49.90%\n",
      "Difference: 0.20%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test': 50098, 'control': 49902}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def test_distribution(sample_size=100000):\n",
    "    \"\"\"Тестирует равномерность распределения.\"\"\"\n",
    "    groups = {'test': 0, 'control': 0}\n",
    "    \n",
    "    for user_id in range(sample_size):\n",
    "        group = get_exp_group(user_id)\n",
    "        groups[group] += 1\n",
    "    \n",
    "    test_percent = (groups['test'] / sample_size) * 100\n",
    "    control_percent = (groups['control'] / sample_size) * 100\n",
    "    \n",
    "    print(f\"Test group: {test_percent:.2f}%\")\n",
    "    print(f\"Control group: {control_percent:.2f}%\")\n",
    "    print(f\"Difference: {abs(test_percent - control_percent):.2f}%\")\n",
    "    \n",
    "    # Проверяем, что разница меньше 1%\n",
    "    assert abs(test_percent - 50) < 1, \"Распределение не 50/50\"\n",
    "    \n",
    "    return groups\n",
    "\n",
    "# Запуск теста\n",
    "test_distribution()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
